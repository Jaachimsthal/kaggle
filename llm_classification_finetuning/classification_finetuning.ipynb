{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9295fc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /root/.cache/modelscope/hub/models/Qwen/Qwen2.5-0.5B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-22 15:04:49,935 - modelscope - INFO - Target directory already exists, skipping creation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /root/.cache/modelscope/hub/models/Qwen/Qwen2.5-0.5B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-22 15:04:52,443 - modelscope - INFO - Target directory already exists, skipping creation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /root/.cache/modelscope/hub/models/Qwen/Qwen2.5-0.5B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-22 15:04:53,645 - modelscope - INFO - Target directory already exists, skipping creation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen2Model(\n",
       "  (embed_tokens): Embedding(151936, 896)\n",
       "  (layers): ModuleList(\n",
       "    (0-23): 24 x Qwen2DecoderLayer(\n",
       "      (self_attn): Qwen2Attention(\n",
       "        (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "        (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "        (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "        (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "      )\n",
       "      (mlp): Qwen2MLP(\n",
       "        (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "        (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "        (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "        (act_fn): SiLUActivation()\n",
       "      )\n",
       "      (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    )\n",
       "  )\n",
       "  (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "  (rotary_emb): Qwen2RotaryEmbedding()\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入AutoModel类，该类允许自动从预训练模型库加载模型\n",
    "from modelscope import AutoModel, AutoModelForCausalLM, AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# 设置预训练模型的检查点名称，这里使用THUDM维护的ChatGLM3-6B模型\n",
    "check_point = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "# 将可选的本地模型路径注释掉，如果需要从本地加载模型，则取消注释并指定正确的本地路径\n",
    "# model_path = \"/home/egcs/models/chatglm3-6b\"\n",
    "# 使用AutoModel的from_pretrained方法加载模型表示信任远程代码，允许从模型仓库执行未验证的代码\n",
    "model: nn.Module = AutoModel.from_pretrained(pretrained_model_name_or_path=check_point, trust_remote_code=True, dtype=\"auto\").half().cuda()\n",
    "# 加载模型对应的分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=check_point)\n",
    "# 加载模型对应的配置\n",
    "conf = AutoConfig.from_pretrained(pretrained_model_name_or_path=check_point)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34970a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2Model(\n",
       "  (embed_tokens): Embedding(151936, 896)\n",
       "  (layers): ModuleList(\n",
       "    (0-23): 24 x Qwen2DecoderLayer(\n",
       "      (self_attn): Qwen2Attention(\n",
       "        (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "        (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "        (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "        (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "      )\n",
       "      (mlp): Qwen2MLP(\n",
       "        (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "        (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "        (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "        (act_fn): SiLUActivation()\n",
       "      )\n",
       "      (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    )\n",
       "  )\n",
       "  (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "  (rotary_emb): Qwen2RotaryEmbedding()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.add_module(module=nn.Linear(896, 2), name=\"classification_layer\") # 兼容PyTorch操作\n",
    "model_from_conf = AutoModel.from_config(config=conf)\n",
    "model_from_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "613a09f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[108386,   3837, 105043, 100165,  11319, 151643],\n",
       "        [ 35946, 100165, 104993,   3837, 104198,  56568],\n",
       "        [102048,  12857,  44928, 151643, 151643, 151643]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 0, 0, 0]])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(\"“你好”\"))\n",
    "# 编码使用\n",
    "inputs = tokenizer([\"你好，你是谁？\", \"我谁也不是，我是你\", \"出口成章\"], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "inputs_ids = inputs['input_ids'].to(\"cuda\")\n",
    "inputs_ids.shape\n",
    "inputs_ids\n",
    "# 解码使用\n",
    "tokenizer.decode(inputs_ids[2])\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fe1eca",
   "metadata": {},
   "source": [
    "# 检视模型（Qwen/Qwen2.5-0.5B-Instruct）\n",
    "\n",
    "## embed_tokens\n",
    "Embedding(151936, 896)，词嵌入层，输入维度为vocab_size=151936，转为896维向量\n",
    "## layers（ModuleList）\n",
    "一个标准的Decoder Only Transformers架构模型，这里Layer为TransformersBlocks；\n",
    "1. 多头自注意力层重复24次：\n",
    "    1. query：表示权重，维度为896*896，使用Linear层便于权重和input序列的矩阵乘法和权重参数的初始化；\n",
    "    2. key：维度为896*128，query @ key.T，query的行数=key.T的列数；\n",
    "    3. value：与key的维度相同，这里k和v的维度为128是因为当前为多头注意力，将128*7分为了7个头；\n",
    "    4. output：最后一个线性输出将输出维度重新设置为896*896；\n",
    "2. MLP（Qwen2MLP，多层感知机层）：是一个多层感知机，负责对经过自注意力机制处理后的向量表示进行非线性变换，以便捕捉更复杂的语义模式。\n",
    "3. layernorm：包含两个两个层归一化，与GPT一致，均为前层归一化和后层归一化，确保反向传播过程中的数值的稳定性；\n",
    "## norm\n",
    "模型的最后一层层归一化\n",
    "## rotary_emb\n",
    "### 概述\n",
    "Rotary Position Embedding, RoPE模块，是一种位置编码技术，用于在Transformer模型中引入序列中token的相对位置信息，与传统绝对位置编码不同，RoPE通过旋转变换将位置信息融入到Query和Key向量中。\n",
    "### 原理\n",
    "将Query和Key的每一对维度（q2i, q2i+1）视作一个二维坐标；\n",
    "根据位置索引pos和一个频率参数，将这个坐标旋转一个角度；\n",
    "旋转角度θ=pos * base^(-2i/d)，角度随位置线性增长，i越大，角度越大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1590f114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2Model(\n",
       "  (embed_tokens): Embedding(151936, 896)\n",
       "  (layers): ModuleList(\n",
       "    (0-23): 24 x Qwen2DecoderLayer(\n",
       "      (self_attn): Qwen2Attention(\n",
       "        (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "        (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "        (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "        (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "      )\n",
       "      (mlp): Qwen2MLP(\n",
       "        (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "        (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "        (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "        (act_fn): SiLUActivation()\n",
       "      )\n",
       "      (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    )\n",
       "  )\n",
       "  (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "  (rotary_emb): Qwen2RotaryEmbedding()\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检视模型\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa8315e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[108386,   3837, 105043, 100165,  11319, 151643],\n",
      "        [ 35946, 100165, 104993,   3837, 104198,  56568],\n",
      "        [102048,  12857,  44928, 151643, 151643, 151643]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 0, 0, 0]], device='cuda:0')}\n",
      "torch.Size([3, 6, 896])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPast(last_hidden_state=tensor([[[ -1.1582,  -0.6299,   1.4277,  ...,   6.9180,   0.4622,   1.4111],\n",
       "         [  2.8145,   5.9492,   4.4766,  ...,   2.1406,   3.9102,  -3.5078],\n",
       "         [  5.2148,   6.3672,   4.6055,  ...,   8.7422,   0.4136,  -8.5625],\n",
       "         [ -2.2637,   3.3730,  -1.2910,  ...,   2.7227,   0.6890,  -7.5312],\n",
       "         [  3.9941,   4.8789,   2.0703,  ...,   2.5059,  -3.2148,  -8.0234],\n",
       "         [ -2.3848,  -0.6816,   5.1914,  ...,   4.0547,   2.9180, -15.1484]],\n",
       "\n",
       "        [[  1.8525,   4.4531,   1.5273,  ...,   7.7227,   1.2178,   0.0757],\n",
       "         [ -4.9336,  -1.3486,  -6.9180,  ...,   2.4961,  -2.9961,  11.0469],\n",
       "         [ -0.1310,   3.7656,   0.7329,  ...,   4.9414,   0.6860,  -4.6328],\n",
       "         [  1.7012,  -0.8330,  -1.4219,  ...,   2.9258,   0.3335,   0.7085],\n",
       "         [  0.9697,   0.5176,  -0.3689,  ...,   0.5933,  -0.9019,  -7.4922],\n",
       "         [ -6.7305,  -0.1810,  -0.9126,  ...,   3.7031,  -0.3247,   7.4336]],\n",
       "\n",
       "        [[ -0.9585,  -3.6055,   4.6133,  ...,   0.9863,  -2.8906,   5.3555],\n",
       "         [ -2.9414,  -5.7227,  -3.5938,  ...,  -5.2461,  -3.5195,   5.9102],\n",
       "         [  0.2705,  -3.8340,  -2.3223,  ...,   1.0176,  -1.5527, -12.7969],\n",
       "         [ -4.0273,   1.4355,   0.8306,  ...,   0.1421,  -2.4004,  -9.4766],\n",
       "         [ -0.8462,   1.1367,  -0.7632,  ...,  -0.1255,  -5.1953,  -5.5586],\n",
       "         [  0.0325,   1.8730,  -1.1357,  ...,   2.0332,  -3.6250,  -9.8359]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型输出\n",
    "inputs_on_gpu = {key: value.to(\"cuda\") for key, value in inputs.items()}\n",
    "print(inputs_on_gpu)\n",
    "outputs = model(**inputs_on_gpu) # **表示解包字典为关键字参数形式，传入函数\n",
    "print(outputs.last_hidden_state.shape) # batch_size, sequence_length, hidden_size\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "71efaeb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassificationModel(\n",
       "  (base_model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 896)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=896, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ClassificationModel(nn.Module):\n",
    "    \"\"\"LLM 二分类任务模型（基于Base Model：Qwen/Qwen2.5-0.5B-Instruct）\n",
    "\n",
    "    Args:\n",
    "        nn (_type_): _description_\n",
    "    \"\"\"\n",
    "    def __init__(self, base_model: nn.Module, hidden_size: int) -> None:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            base_model (torch.Module): 基础模型\n",
    "            hidden_size (int): 基础Transformers层hidden size\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.net = nn.Sequential(nn.Linear(in_features=hidden_size, out_features=2, dtype=torch.half))\n",
    "        \n",
    "    def forward(self, inputs_ids: torch.Tensor, attention_mask: torch.Tensor=None) -> torch.Tensor:\n",
    "        \"\"\"前向传播\n",
    "\n",
    "        Args:\n",
    "            inputs_ids (torch.Tensor): 输入Token IDS\n",
    "            attention_mask (torch.Tensor, optional): 填充向量表示. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: 分类输出\n",
    "        \"\"\"\n",
    "        base_model_outs = self.base_model(inputs_ids, attention_mask)\n",
    "        return self.net(base_model_outs.last_hidden_state)\n",
    "classification_model = ClassificationModel(base_model=model, hidden_size=model.config.hidden_size).to(\"cuda\")\n",
    "classification_model(inputs_ids=inputs_ids)\n",
    "classification_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397be949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下即可进行PyTorch的分类微调"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
