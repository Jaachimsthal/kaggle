{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9295fc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /root/.cache/modelscope/hub/models/Qwen/Qwen2.5-0.5B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 11:07:34,505 - modelscope - INFO - Target directory already exists, skipping creation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /root/.cache/modelscope/hub/models/Qwen/Qwen2.5-0.5B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 11:07:43,470 - modelscope - INFO - Target directory already exists, skipping creation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /root/.cache/modelscope/hub/models/Qwen/Qwen2.5-0.5B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 11:07:48,163 - modelscope - INFO - Target directory already exists, skipping creation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen2Model(\n",
       "  (embed_tokens): Embedding(151936, 896)\n",
       "  (layers): ModuleList(\n",
       "    (0-23): 24 x Qwen2DecoderLayer(\n",
       "      (self_attn): Qwen2Attention(\n",
       "        (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "        (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "        (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "        (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "      )\n",
       "      (mlp): Qwen2MLP(\n",
       "        (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "        (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "        (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "        (act_fn): SiLUActivation()\n",
       "      )\n",
       "      (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    )\n",
       "  )\n",
       "  (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "  (rotary_emb): Qwen2RotaryEmbedding()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入AutoModel类，该类允许自动从预训练模型库加载模型\n",
    "from modelscope import AutoModel, AutoModelForCausalLM, AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# 设置预训练模型的检查点名称，这里使用THUDM维护的ChatGLM3-6B模型\n",
    "check_point = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "# 将可选的本地模型路径注释掉，如果需要从本地加载模型，则取消注释并指定正确的本地路径\n",
    "# model_path = \"/home/egcs/models/chatglm3-6b\"\n",
    "# 使用AutoModel的from_pretrained方法加载模型表示信任远程代码，允许从模型仓库执行未验证的代码\n",
    "model: nn.Module = AutoModel.from_pretrained(pretrained_model_name_or_path=check_point, trust_remote_code=True, dtype=\"auto\").half().cuda()\n",
    "# 加载模型对应的分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=check_point)\n",
    "# 加载模型对应的配置\n",
    "conf = AutoConfig.from_pretrained(pretrained_model_name_or_path=check_point)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34970a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2Model(\n",
       "  (embed_tokens): Embedding(151936, 896)\n",
       "  (layers): ModuleList(\n",
       "    (0-23): 24 x Qwen2DecoderLayer(\n",
       "      (self_attn): Qwen2Attention(\n",
       "        (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "        (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "        (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "        (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "      )\n",
       "      (mlp): Qwen2MLP(\n",
       "        (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "        (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "        (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "        (act_fn): SiLUActivation()\n",
       "      )\n",
       "      (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    )\n",
       "  )\n",
       "  (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "  (rotary_emb): Qwen2RotaryEmbedding()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.add_module(module=nn.Linear(896, 2), name=\"classification_layer\") # 兼容PyTorch操作\n",
    "model_from_conf = AutoModel.from_config(config=conf)\n",
    "model_from_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "613a09f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[108386,   3837, 105043, 100165,  11319, 151643],\n",
       "        [ 35946, 100165, 104993,   3837, 104198,  56568],\n",
       "        [102048,  12857,  44928, 151643, 151643, 151643]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 0, 0, 0]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(\"“你好”\"))\n",
    "# 编码使用\n",
    "inputs = tokenizer([\"你好，你是谁？\", \"我谁也不是，我是你\", \"出口成章\"], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "inputs_ids = inputs['input_ids'].to(\"cuda\")\n",
    "inputs_ids.shape\n",
    "inputs_ids\n",
    "# 解码使用\n",
    "tokenizer.decode(inputs_ids[2])\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fe1eca",
   "metadata": {},
   "source": [
    "# 检视模型（Qwen/Qwen2.5-0.5B-Instruct）\n",
    "\n",
    "## embed_tokens\n",
    "Embedding(151936, 896)，词嵌入层，输入维度为vocab_size=151936，转为896维向量\n",
    "## layers（ModuleList）\n",
    "一个标准的Decoder Only Transformers架构模型，这里Layer为TransformersBlocks；\n",
    "1. 多头自注意力层重复24次：\n",
    "    1. query：表示权重，维度为896*896，使用Linear层便于权重和input序列的矩阵乘法和权重参数的初始化；\n",
    "    2. key：维度为896*128，query @ key.T，query的行数=key.T的列数；\n",
    "    3. value：与key的维度相同，这里k和v的维度为128是因为当前为多头注意力，将128*7分为了7个头；\n",
    "    4. output：最后一个线性输出将输出维度重新设置为896*896；\n",
    "2. MLP（Qwen2MLP，多层感知机层）：是一个多层感知机，负责对经过自注意力机制处理后的向量表示进行非线性变换，以便捕捉更复杂的语义模式。\n",
    "3. layernorm：包含两个两个层归一化，与GPT一致，均为前层归一化和后层归一化，确保反向传播过程中的数值的稳定性；\n",
    "## norm\n",
    "模型的最后一层层归一化\n",
    "## rotary_emb\n",
    "### 概述\n",
    "Rotary Position Embedding, RoPE模块，是一种位置编码技术，用于在Transformer模型中引入序列中token的相对位置信息，与传统绝对位置编码不同，RoPE通过旋转变换将位置信息融入到Query和Key向量中。\n",
    "### 原理\n",
    "将Query和Key的每一对维度（q2i, q2i+1）视作一个二维坐标；\n",
    "根据位置索引pos和一个频率参数，将这个坐标旋转一个角度；\n",
    "旋转角度θ=pos * base^(-2i/d)，角度随位置线性增长，i越大，角度越大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1590f114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2Model(\n",
       "  (embed_tokens): Embedding(151936, 896)\n",
       "  (layers): ModuleList(\n",
       "    (0-23): 24 x Qwen2DecoderLayer(\n",
       "      (self_attn): Qwen2Attention(\n",
       "        (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "        (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "        (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "        (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "      )\n",
       "      (mlp): Qwen2MLP(\n",
       "        (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "        (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "        (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "        (act_fn): SiLUActivation()\n",
       "      )\n",
       "      (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    )\n",
       "  )\n",
       "  (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "  (rotary_emb): Qwen2RotaryEmbedding()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检视模型\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4aa8315e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[108386,   3837, 105043, 100165,  11319, 151643],\n",
      "        [ 35946, 100165, 104993,   3837, 104198,  56568],\n",
      "        [102048,  12857,  44928, 151643, 151643, 151643]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 0, 0, 0]], device='cuda:0')}\n",
      "torch.Size([3, 6, 896])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPast(last_hidden_state=tensor([[[ -1.1582,  -0.6299,   1.4277,  ...,   6.9180,   0.4622,   1.4111],\n",
       "         [  2.8145,   5.9492,   4.4766,  ...,   2.1406,   3.9102,  -3.5078],\n",
       "         [  5.2148,   6.3672,   4.6055,  ...,   8.7422,   0.4136,  -8.5625],\n",
       "         [ -2.2637,   3.3730,  -1.2910,  ...,   2.7227,   0.6890,  -7.5312],\n",
       "         [  3.9941,   4.8789,   2.0703,  ...,   2.5059,  -3.2148,  -8.0234],\n",
       "         [ -2.3848,  -0.6816,   5.1914,  ...,   4.0547,   2.9180, -15.1484]],\n",
       "\n",
       "        [[  1.8525,   4.4531,   1.5273,  ...,   7.7227,   1.2178,   0.0757],\n",
       "         [ -4.9336,  -1.3486,  -6.9180,  ...,   2.4961,  -2.9961,  11.0469],\n",
       "         [ -0.1310,   3.7656,   0.7329,  ...,   4.9414,   0.6860,  -4.6328],\n",
       "         [  1.7012,  -0.8330,  -1.4219,  ...,   2.9258,   0.3335,   0.7085],\n",
       "         [  0.9697,   0.5176,  -0.3689,  ...,   0.5933,  -0.9019,  -7.4922],\n",
       "         [ -6.7305,  -0.1810,  -0.9126,  ...,   3.7031,  -0.3247,   7.4336]],\n",
       "\n",
       "        [[ -0.9585,  -3.6055,   4.6133,  ...,   0.9863,  -2.8906,   5.3555],\n",
       "         [ -2.9414,  -5.7227,  -3.5938,  ...,  -5.2461,  -3.5195,   5.9102],\n",
       "         [  0.2705,  -3.8340,  -2.3223,  ...,   1.0176,  -1.5527, -12.7969],\n",
       "         [ -4.0273,   1.4355,   0.8306,  ...,   0.1421,  -2.4004,  -9.4766],\n",
       "         [ -0.8462,   1.1367,  -0.7632,  ...,  -0.1255,  -5.1953,  -5.5586],\n",
       "         [  0.0325,   1.8730,  -1.1357,  ...,   2.0332,  -3.6250,  -9.8359]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型输出\n",
    "inputs_on_gpu = {key: value.to(\"cuda\") for key, value in inputs.items()}\n",
    "print(inputs_on_gpu)\n",
    "outputs = model(**inputs_on_gpu) # **表示解包字典为关键字参数形式，传入函数\n",
    "print(outputs.last_hidden_state.shape) # batch_size, sequence_length, hidden_size\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71efaeb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassificationModel(\n",
       "  (base_model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 896)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=896, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ClassificationModel(nn.Module):\n",
    "    \"\"\"LLM 二分类任务模型（基于Base Model：Qwen/Qwen2.5-0.5B-Instruct）\n",
    "\n",
    "    Args:\n",
    "        nn (_type_): _description_\n",
    "    \"\"\"\n",
    "    def __init__(self, base_model: nn.Module, hidden_size: int) -> None:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            base_model (torch.Module): 基础模型\n",
    "            hidden_size (int): 基础Transformers层hidden size\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.net = nn.Sequential(nn.Linear(in_features=hidden_size, out_features=2, dtype=torch.half))\n",
    "        \n",
    "    def forward(self, inputs_ids: torch.Tensor, attention_mask: torch.Tensor=None) -> torch.Tensor:\n",
    "        \"\"\"前向传播\n",
    "\n",
    "        Args:\n",
    "            inputs_ids (torch.Tensor): 输入Token IDS\n",
    "            attention_mask (torch.Tensor, optional): 填充向量表示. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: 分类输出\n",
    "        \"\"\"\n",
    "        base_model_outs = self.base_model(inputs_ids, attention_mask)\n",
    "        return self.net(base_model_outs.last_hidden_state)\n",
    "classification_model = ClassificationModel(base_model=model, hidden_size=model.config.hidden_size).to(\"cuda\")\n",
    "classification_model(inputs_ids=inputs_ids)\n",
    "classification_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "397be949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTPSConnectionPool(host='storage.googleapis.com', port=443): Max retries exceeded with url: /kaggle-competitions-data/kaggle-v2/86518/9809560/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1769304116&Signature=esrVEigd5wXdwgva2GnjEkaIs14vRkrWMusimofgzMVdiKJbUxJNDeA%2FNZWd1prC1SLfcFOLM70Iq3xKacZhU%2BOThqKfFXh5f1pxDxng4OrojoHTkdajhUHiorxLjSejbOMH6xwytZLF7BtvJDyN%2B2FAonDSFQC73Jh3clnCOeCOYeszuqaFA2BiS5zUiuIw9ZMkvJbvzvuwtcm%2FX3mhEwu%2FkCjTUQbdwu4aqLqU4Q2r1%2BNob6Jd1y7qPcJIL%2BipuxhKu9TaGG%2FZ7R0aj5XXK51gGXqKqg2HshEMr7pAKDLmgKWvRUQu8ON71Cbj%2FllI4pJfuPboPSFe%2BPW54jJwlg%3D%3D&response-content-disposition=attachment%3B+filename%3Dllm-classification-finetuning.zip (Caused by SSLError(SSLZeroReturnError(6, 'TLS/SSL connection has been closed (EOF) (_ssl.c:1147)')))\n"
     ]
    }
   ],
   "source": [
    "# 首先加载Kaggle数据集\n",
    "!kaggle competitions download -c llm-classification-finetuning\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "path = 'llm-classification-finetuning'\n",
    "if not os.path.exists(path=path):\n",
    "    os.makedirs(name=path)\n",
    "    fp = zipfile.ZipFile(file='llm-classification-finetuning.zip', mode='r')\n",
    "    fp.extractall(path)\n",
    "\n",
    "train_csv_data = pd.read_csv(filepath_or_buffer='llm-classification-finetuning/train.csv')\n",
    "test_csv_data = pd.read_csv(filepath_or_buffer='llm-classification-finetuning/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee0551fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 30192,\n",
       " 'model_a': 'gpt-4-1106-preview',\n",
       " 'model_b': 'gpt-4-0613',\n",
       " 'prompt': '[\"Is it morally right to try to have a certain percentage of females on managerial positions?\",\"OK, does pineapple belong on a pizza? Relax and give me fun answer.\"]',\n",
       " 'response_a': '[\"The question of whether it is morally right to aim for a certain percentage of females in managerial positions is a complex ethical issue that involves considerations of fairness, equality, diversity, and discrimination.\\\\n\\\\nHere are some arguments in favor of and against such policies:\\\\n\\\\n**Arguments in favor:**\\\\n\\\\n1. **Correcting Historical Inequities:** Women have historically been underrepresented in leadership roles due to various cultural, institutional, and social barriers. Aiming for a specific percentage can be seen as a corrective measure to address past and ongoing discrimination.\\\\n\\\\n2. **Promoting Diversity:** Diverse leadership teams can enhance decision-making and represent a broader range of perspectives. This can lead to better outcomes for organizations and society as a whole.\\\\n\\\\n3. **Equality of Opportunity:** Setting targets for female representation in management can help ensure that women have equal opportunities to advance in their careers.\\\\n\\\\n4. **Role Modeling:** Increased visibility of female leaders can inspire and encourage other women and girls to pursue leadership roles.\\\\n\\\\n**Arguments against:**\\\\n\\\\n1. **Reverse Discrimination:** Setting a quota for female representation might lead to the perception or reality of reverse discrimination, where men might be overlooked for positions despite being qualified, simply to meet the gender target.\\\\n\\\\n2. **Meritocracy Concerns:** Critics argue that employment and promotion should be based solely on merit and qualifications, not gender. They fear that quotas could compromise the quality of leadership if less qualified individuals are promoted to meet gender targets.\\\\n\\\\n3. **Tokenism:** There is a risk that women appointed to meet quotas might be seen as \\\\\"tokens,\\\\\" undermining their legitimacy and potentially leading to resentment among colleagues.\\\\n\\\\n4. **Oversimplification of Diversity:** Focusing only on gender might overlook other important aspects of diversity, such as race, ethnicity, socioeconomic background, or sexual orientation.\\\\n\\\\nUltimately, the morality of aiming for a certain percentage of females in managerial positions depends on one\\'s ethical framework and the context in which such policies are implemented. Proponents of gender diversity targets often argue that these measures are necessary as a transitional mechanism to create a level playing field, while opponents may argue for a \\\\\"color-blind\\\\\" or \\\\\"gender-blind\\\\\" approach to hiring and promotions.\\\\n\\\\nOrganizations and societies must carefully consider the implications of these strategies and strive to implement policies that promote fairness and equality while minimizing negative consequences. It is also important to address the root causes of gender inequality, such as unconscious bias, work-life balance challenges, and lack of supportive policies, to create an environment where everyone has the opportunity to succeed based on their capabilities and contributions.\",\"Ah, the age-old culinary conundrum that has divided nations and dinner tables: does pineapple belong on a pizza? The tropical twist of pineapple on pizza, known as Hawaiian pizza, is a hotly debated topic where taste buds battle and pizza purists protest.\\\\n\\\\nLet\\'s slice into the debate with a zest of fun:\\\\n\\\\n**Team Pineapple:** \\\\\"Absolutely, yes! Pineapple on pizza is like a beach party in your mouth. The sweet juiciness of pineapple chunks frolicking with savory ham or bacon creates a flavor wave that surfs across the cheesy ocean of deliciousness. It\\'s the Mardi Gras of pizzas, where sweet meets savory in a jubilant jamboree!\\\\\"\\\\n\\\\n**Team No-Pineapple:** \\\\\"No way, not in a million pizzas! Pineapple is a fruit that should be sunbathing on a tropical fruit platter, not freeloading on a sacred slice of pizza. The thought of warm, melty cheese conspiring with pineapple\\'s sugary mischief is enough to make Italian ancestors turn in their tomato patches. Keep the pineapple in the fruit salad where it belongs!\\\\\"\\\\n\\\\nAt the end of the day, whether pineapple belongs on pizza is a matter of personal taste. Some say it\\'s a match made in heaven, others say it\\'s a culinary crime. But let\\'s face it, in the world of pizza toppings, where you can find everything from anchovies to zucchini, there\\'s room for a little pineapple pizzazz. So, if your taste buds crave that sweet and tangy twist, go ahead and let your pineapple flag fly atop that glorious cheese-covered dough. Bon app\\\\u00e9tit, or as they say in pineapple paradise, \\\\\"Aloha-ppetite!\\\\\" \\\\ud83c\\\\udf4d\\\\ud83c\\\\udf55\"]',\n",
       " 'response_b': '[\"As an AI, I don\\'t have personal beliefs or opinions. However, I can tell you that the question of gender quotas in managerial positions is a complex one and positions can vary. Advocates argue that such measures can help correct historical imbalances, promote diversity, and may lead to better decision-making. Critics may argue that positions should be based purely on merit, and that quotas could potentially lead to tokenism or unqualified candidates being promoted. Morality can be subjective and differs from person to person based on their personal beliefs, cultural background, and values. It\\'s a topic with valid arguments on both sides, and it\\'s up to each individual or organization to decide what they believe is right.\",\"As an AI, I don\\'t eat, so I don\\'t have personal preferences. But, in the world of pizza, the pineapple topping is a hotly debated topic! Some people love the sweet and savory mix it brings to a pizza, a flavor combination made famous by the Hawaiian pizza. Others firmly believe that the sweetness of the fruit has no place on a pizza. It\\'s a pizza puzzle that might never be solved. So, whether pineapple belongs on a pizza or not, it truly depends on your taste buds!\"]',\n",
       " 'winner_model_a': 1,\n",
       " 'winner_model_b': 0,\n",
       " 'winner_tie': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datasets库（兼容处理Kaggle数据集）\n",
    "from datasets import load_dataset\n",
    "# 读取数据集（并且可以同时加载多个数据集，并且对不同数据集划分指定文件）\n",
    "# train_dataset = load_dataset(\"csv\", data_files=\"llm-classification-finetuning/train.csv\")\n",
    "# all_dataset = load_dataset(\"csv\", data_files=[\"llm-classification-finetuning/train.csv\", \"llm-classification-finetuning/test.csv\"])\n",
    "all_dataset = load_dataset(\"csv\", data_files={\n",
    "    \"train\": \"llm-classification-finetuning/train.csv\",\n",
    "    \"test\" : \"llm-classification-finetuning/test.csv\"\n",
    "})\n",
    "all_dataset['train'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
